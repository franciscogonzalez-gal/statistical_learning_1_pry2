# Proyecto 2 - Statistical Learning I: Clasificaci√≥n de Incumplimiento de Pr√©stamos

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/franciscogonzalez-gal/statistical_learning_1_pry2/blob/main/proyecto_2_clasificacion.ipynb)

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un sistema de clasificaci√≥n para predecir el incumplimiento de pr√©stamos utilizando t√©cnicas de aprendizaje autom√°tico supervisado. El objetivo principal es construir y comparar diferentes modelos de clasificaci√≥n que puedan predecir si un solicitante de pr√©stamo incumplir√° con sus pagos (`defaulted`).

**Autor:** Francisco Gonz√°lez  
**Carnet:** 24002914  
**Curso:** Statistical Learning I

## üéØ Objetivo

Desarrollar modelos de clasificaci√≥n que permitan predecir el riesgo de incumplimiento de pr√©stamos bas√°ndose en caracter√≠sticas demogr√°ficas, financieras y de historial crediticio de los solicitantes.

## üìä Dataset

El proyecto utiliza un conjunto de datos de solicitudes de pr√©stamos que incluye las siguientes variables:

### Variables del Dataset

- **id**: Identificador √∫nico del solicitante
- **age**: Edad del solicitante
- **income**: Ingresos del solicitante
- **credit_score**: Puntaje de cr√©dito
- **loan_amount**: Monto del pr√©stamo solicitado
- **loan_term_months**: Plazo del pr√©stamo en meses
- **employment_status**: Estado laboral
- **marital_status**: Estado civil
- **num_dependents**: N√∫mero de dependientes
- **education_level**: Nivel de educaci√≥n
- **home_ownership**: Tipo de propiedad de vivienda
- **city**: Ciudad de residencia
- **application_date**: Fecha de solicitud
- **savings_balance**: Balance de ahorros
- **checking_balance**: Balance de cuenta corriente
- **defaulted**: Variable objetivo (0 = No incumpli√≥, 1 = Incumpli√≥)

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as Utilizadas

El proyecto est√° desarrollado en Python y utiliza las siguientes librer√≠as principales:

```python
# An√°lisis de datos
- pandas
- numpy

# Visualizaci√≥n
- matplotlib
- seaborn

# Machine Learning
- scikit-learn
  - LogisticRegression
  - GaussianNB
  - LinearSVC (SVM)
  - RandomForestClassifier
  - GridSearchCV
  - Pipeline
  - ColumnTransformer

# Persistencia
- joblib

# Entorno
- Google Colab
```

## üìÅ Estructura del Proyecto

```
statistical_learning_1_pry2/
‚îÇ
‚îú‚îÄ‚îÄ proyecto_2_clasificacion.ipynb  # Notebook principal con todo el an√°lisis
‚îú‚îÄ‚îÄ LICENSE                          # Licencia CC0 1.0 Universal
‚îî‚îÄ‚îÄ README.md                        # Este archivo
```

## üîç Metodolog√≠a

El proyecto sigue un flujo de trabajo estructurado de ciencia de datos:

### 1. Importaci√≥n de Librer√≠as
Carga de todas las dependencias necesarias para el an√°lisis.

### 2. Carga de Datos
Importaci√≥n del dataset desde Google Drive.

### 3. Definici√≥n de Variables
Identificaci√≥n y documentaci√≥n de todas las variables del dataset.

### 4. An√°lisis Exploratorio de Datos (EDA)
- An√°lisis de distribuciones
- Identificaci√≥n de valores faltantes
- An√°lisis de correlaciones
- Visualizaciones estad√≠sticas
- Detecci√≥n de desbalance de clases

### 5. Limpieza de Datos e Imputaci√≥n
- Tratamiento de valores faltantes
- Manejo de outliers
- Estandarizaci√≥n de formatos

### 6. Ingenier√≠a de Caracter√≠sticas
- Creaci√≥n de pipeline de preprocesamiento
- Transformaci√≥n de variables categ√≥ricas (One-Hot Encoding)
- Escalado de variables num√©ricas (StandardScaler)
- Uso de `ColumnTransformer` para procesar diferentes tipos de variables

### 7. Separaci√≥n de Datos
Divisi√≥n del dataset en conjuntos de entrenamiento y prueba.

### 8. Definici√≥n de Modelos y Pipelines
Configuraci√≥n de cuatro modelos de clasificaci√≥n:

#### a) Regresi√≥n Log√≠stica
- Solver: SAGA
- Penalizaci√≥n: L1 y L2 (b√∫squeda de hiperpar√°metros)
- Class weight: balanced
- Par√°metro C: [0.01, 0.1, 1, 10]

#### b) Naive Bayes Gaussiano
- Modelo probabil√≠stico base
- Sin hiperpar√°metros a optimizar

#### c) SVM Lineal
- LinearSVC con calibraci√≥n de probabilidades
- Dual: False
- Class weight: balanced
- Par√°metro C: b√∫squeda con GridSearchCV

#### d) Random Forest
- Conjunto de √°rboles de decisi√≥n
- Optimizaci√≥n de hiperpar√°metros:
  - n_estimators
  - max_depth
  - min_samples_split
  - min_samples_leaf

### 9. Entrenamiento y Validaci√≥n
- Uso de `GridSearchCV` para b√∫squeda de hiperpar√°metros
- Validaci√≥n cruzada durante el entrenamiento
- Selecci√≥n de los mejores modelos

### 10. Evaluaci√≥n en Conjunto de Prueba
Evaluaci√≥n exhaustiva de cada modelo con:
- **Matriz de confusi√≥n**: Visualizaci√≥n de predicciones correctas e incorrectas
- **M√©tricas de clasificaci√≥n**:
  - Precision
  - Recall
  - F1-Score
  - Accuracy
- **Curva ROC**: An√°lisis del trade-off entre tasa de verdaderos positivos y falsos positivos
- **AUC**: √Årea bajo la curva ROC

### 11. Persistencia de Modelos
Almacenamiento de los modelos entrenados usando `joblib` para uso futuro.

## üöÄ C√≥mo Usar Este Proyecto

### Opci√≥n 1: Google Colab (Recomendado)
1. Haz clic en el badge "Open in Colab" al inicio de este README
2. El notebook se abrir√° en Google Colab
3. Aseg√∫rate de tener el dataset en tu Google Drive
4. Ejecuta las celdas secuencialmente

### Opci√≥n 2: Entorno Local

#### Requisitos Previos
- Python 3.7 o superior
- pip (gestor de paquetes de Python)

#### Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/statistical_learning_1_pry2.git
cd statistical_learning_1_pry2

# Instalar dependencias
pip install pandas numpy matplotlib seaborn scikit-learn jupyter joblib
```

#### Ejecutar el Notebook

```bash
# Iniciar Jupyter Notebook
jupyter notebook proyecto_2_clasificacion.ipynb
```

**Nota:** Deber√°s modificar las rutas de acceso a los datos seg√∫n tu configuraci√≥n local.

## üìà Resultados Principales

El proyecto implementa y compara cuatro modelos de clasificaci√≥n:

1. **Regresi√≥n Log√≠stica**: Modelo lineal con regularizaci√≥n L1/L2
2. **Naive Bayes Gaussiano**: Modelo probabil√≠stico basado en el teorema de Bayes
3. **SVM Lineal**: Clasificador de m√°xima margen con calibraci√≥n de probabilidades
4. **Random Forest**: Ensemble de √°rboles de decisi√≥n

Cada modelo se eval√∫a en t√©rminos de:
- Capacidad de predicci√≥n (Accuracy)
- Balance entre Precision y Recall
- Capacidad de discriminaci√≥n (AUC-ROC)
- Matriz de confusi√≥n

## üîÑ Pipeline de Preprocesamiento

El proyecto implementa un pipeline automatizado que:

1. **Variables Num√©ricas**:
   - Imputa valores faltantes con la mediana
   - Aplica estandarizaci√≥n (StandardScaler)

2. **Variables Categ√≥ricas**:
   - Imputa valores faltantes con el valor m√°s frecuente
   - Aplica One-Hot Encoding

Este pipeline garantiza que el preprocesamiento se aplique de manera consistente tanto en entrenamiento como en predicci√≥n.

## üìù Conclusiones y Recomendaciones

El an√°lisis completo de conclusiones y recomendaciones se encuentra en la secci√≥n 11 del notebook. Se recomienda revisar:
- Comparaci√≥n de rendimiento entre modelos
- An√°lisis de caracter√≠sticas m√°s importantes
- Recomendaciones para implementaci√≥n pr√°ctica
- Posibles mejoras futuras

## üìÑ Licencia

Este proyecto est√° licenciado bajo [CC0 1.0 Universal](LICENSE) - Dominio P√∫blico.

Puedes copiar, modificar, distribuir y ejecutar el trabajo, incluso para prop√≥sitos comerciales, sin pedir permiso.

## ü§ù Contribuciones

Este proyecto es parte de un trabajo acad√©mico. Si deseas contribuir o tienes sugerencias, si√©ntete libre de abrir un issue o pull request.

## üìß Contacto

**Francisco Gonz√°lez**  
Carnet: 24002914

---

‚≠ê Si este proyecto te resulta √∫til, considera darle una estrella en GitHub!
